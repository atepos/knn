{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "# Load data from file\n",
    "with open(\"data.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Update score-to-label mapping to handle fractional scores with step 0.25 (e.g., 0.0, 0.25, 0.5, ..., 4.0)\n",
    "score_to_label = {\n",
    "    i * 0.25: int(i) for i in range(17)\n",
    "}  # Generates scores from 0.0 to 4.0 with a step of 0.25\n",
    "label_to_score = {v: k for k, v in score_to_label.items()}\n",
    "\n",
    "\n",
    "# Preprocess the data\n",
    "def preprocess_data(data):\n",
    "    random.shuffle(data)\n",
    "    df = pd.DataFrame(data)\n",
    "    # Ensure that scores are valid before mapping to labels\n",
    "    df[\"label\"] = df[\"score\"].map(score_to_label)\n",
    "    df[\"text\"] = df[\"questionText\"] + \" \" + df[\"answerText\"]\n",
    "    df = df.dropna(subset=[\"label\"])  # Remove rows where 'label' is NaN\n",
    "    df = df.drop(columns=[\"questionNumber\", \"score\", \"questionText\", \"answerText\"])\n",
    "    return df\n",
    "\n",
    "\n",
    "# Split data (80% train, 10% val, 10% test)\n",
    "data_df = preprocess_data(data)\n",
    "train_size = int(0.8 * len(data_df))\n",
    "val_size = int(0.1 * len(data_df))\n",
    "\n",
    "train_df = data_df[:train_size]\n",
    "val_df = data_df[train_size : train_size + val_size]\n",
    "test_df = data_df[train_size + val_size :]\n",
    "\n",
    "datasets = DatasetDict(\n",
    "    {\n",
    "        \"train\": Dataset.from_pandas(train_df),\n",
    "        \"validation\": Dataset.from_pandas(val_df),\n",
    "        \"test\": Dataset.from_pandas(test_df),\n",
    "    }\n",
    ")\n",
    "\n",
    "datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)\n",
    "\n",
    "\n",
    "tokenized_datasets = datasets.map(preprocess_function, batched=True)\n",
    "\n",
    "from transformers import DataCollatorWithPadding\n",
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert/distilbert-base-uncased\",\n",
    "    num_labels=len(label_to_score),\n",
    "    id2label=label_to_score,\n",
    "    label2id=score_to_label,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"results\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=6,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "results = []\n",
    "tokenizer_kwargs = {\"padding\": True, \"truncation\": True, \"max_length\": 512}\n",
    "for sample in datasets[\"test\"]:\n",
    "    prediction = classifier(sample[\"text\"], **tokenizer_kwargs)[0]\n",
    "    predicted_label = prediction[\"label\"]\n",
    "    predicted_score = prediction[\"score\"]\n",
    "    results.append(\n",
    "        {\n",
    "            \"true_label\": label_to_score[sample[\"label\"]],\n",
    "            \"predicted_label\": predicted_label,\n",
    "            \"predicted_score\": predicted_score,\n",
    "            \"text\": sample[\"text\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Display the first few results\n",
    "for result in random.choices(results, k=5):\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "true_scores = [r[\"true_label\"] for r in results]\n",
    "predicted_scores = [r[\"predicted_score\"] for r in results]\n",
    "\n",
    "mae = mean_absolute_error(true_scores, predicted_scores)\n",
    "print(f\"Mean Absolute Error: {mae}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
